{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qinfo = pd.read_csv('data/QInfo.csv')\n",
    "Qinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qbody = pd.read_csv('data/Qbody.csv')\n",
    "Qbody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qbody.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_html = Qbody['Body'][442]\n",
    "sample_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(sample_html, 'html.parser')\n",
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_question(question_html):\n",
    "    soup = BeautifulSoup(question_html, 'html.parser')\n",
    "    txt = soup.text.replace('\\xa0', ' ').split('\\n \\n')[0]\n",
    "    #match = re.search(r'(.+?\\n\\n)', txt, re.DOTALL)\n",
    "    #txt = match.group(0)\n",
    "    txt = txt.replace('-', ' ')\n",
    "    txt = txt.replace('\\n', ' ')\n",
    "    return re.sub(r'[^\\w\\s]', '', txt).rstrip().lower()\n",
    "parse_question(Qbody['Body'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qbody['text'] = Qbody['Body'].apply(parse_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "def update_set(txt):\n",
    "    vocab.update(txt.split())\n",
    "Qbody['text'].apply(update_set)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'word' : list(vocab)\n",
    "    }\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_freq_fnc(doc):\n",
    "    def term_freq(word):\n",
    "        doc_words = doc.split()\n",
    "        return (doc_words.count(word)/len(doc_words))\n",
    "    return term_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freq = term_freq_fnc(Qbody['text'][0])\n",
    "tmp_df = df['word'].apply(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df[tmp_df>0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(Qbody['text']):\n",
    "    term_freq = term_freq_fnc(doc)\n",
    "    df[f'TF{i+1}'] = df['word'].apply(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_docs = len(Qbody['text'])\n",
    "no_of_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cols = [f'TF{i+1}' for i in range(no_of_docs)]\n",
    "doc_freq = np.sum( (df[tf_cols] > 0).to_numpy(), axis=1, keepdims=True)\n",
    "doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = np.log(no_of_docs / doc_freq)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = df[tf_cols].to_numpy()\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tf_idf.sum(axis=1)\n",
    "np.where(tmp <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_DF = pd.DataFrame(\n",
    "    tf_idf,\n",
    "    columns=[f'TF_IDF{i+1}' for i in range(no_of_docs)]\n",
    ")\n",
    "tfidf_DF['word'] = df['word']\n",
    "tfidf_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_DF.iloc[438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a sample 2D NumPy array\n",
    "array_2d = np.array([\n",
    "    [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9, 3, 2, 3, 8, 4],\n",
    "    [4, 2, 5, 7, 3, 1, 8, 3, 5, 6, 1, 9, 4, 2, 7, 8, 6, 1, 3, 5]\n",
    "])\n",
    "\n",
    "# Find the positions of the highest 20 values in each row\n",
    "k = 2\n",
    "highest_positions = []\n",
    "for row in array_2d:\n",
    "    partitioned_indices = np.argpartition(row, -k)[-k:]\n",
    "    sorted_indices = partitioned_indices[np.argsort(row[partitioned_indices])]\n",
    "    highest_positions.append(sorted_indices)\n",
    "\n",
    "print(f\"Positions of the highest {k} values in each row:\")\n",
    "for i, positions in enumerate(highest_positions):\n",
    "    print(f\"Row {i}: {positions}\", [array_2d[i, p] for p in positions])\n",
    "np.array(highest_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "highest_positions = []\n",
    "for row in tf_idf:\n",
    "    partitioned_indices = np.argpartition(row, -k)[-k:]\n",
    "    sorted_indices = partitioned_indices[np.argsort(row[partitioned_indices])]\n",
    "    highest_positions.append(sorted_indices)\n",
    "highest_positions = np.array(highest_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{(highest_positions.size * highest_positions.itemsize)//(1024)} kb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table = pd.DataFrame(\n",
    "    highest_positions,\n",
    "    columns=[f'DOC {i}' for i in range(20)]\n",
    ")\n",
    "lookup_table['word'] = df['word']\n",
    "lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searh_word = \"apple\"\n",
    "\n",
    "idx = np.where((lookup_table['word'] == searh_word).to_numpy())[0]\n",
    "lookup_table.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_QID(doc_no):\n",
    "    return Qbody['QID'][doc_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f'DOC {i}' for i in range(20)]\n",
    "for col in cols:\n",
    "    lookup_table[col] = lookup_table[col].apply(map_to_QID)\n",
    "lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searh_word = \"apple\"\n",
    "\n",
    "idx = np.where((lookup_table['word'] == searh_word).to_numpy())[0]\n",
    "if idx.size == 0:\n",
    "    print('Not found')\n",
    "else:\n",
    "    idx = idx[0]\n",
    "    doc_no = lookup_table['DOC 19'][idx]\n",
    "    print(Qbody['text'][doc_no])\n",
    "    print(Qbody['QID'][doc_no])\n",
    "    print(Qinfo.iloc[doc_no - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup table and Qinfo would be used by the app\n",
    "Qinfo.to_csv('QINFO.csv', index=False, columns=Qinfo.columns[1:])\n",
    "lookup_table.to_csv('LOOKUP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
